---
layout: post
title:  "IMedtrainer - Perceptual Learning in Medical Images"
date:   2018-05-02
categories: mediator feature
image: /assets/article_images/2018-05-02-imedtrainer/medicalimage.jpg
---

# Overview

## About

This is a project from User Interface Design and Implementation's class project(CSci5115), where I learned about the process of research process and research design. The project, IMedtrainer is inspired by human perceptual learning research conducted by our teammate, [Sha Li](https://www.researchgate.net/profile/Sha_Li38). IMedtrainer aims to provide a mobile platform for medical student to perform practice in interpreting medical outside class period and curricular training. 

This project is aim to help us learn through the research process and research design.    
 
## My Role

I participate in interviews and conducted a couple of contextual inquiries. I also took part in the ideation processs by providing different ideas about the product design. when it comes to iterative design phase, I lead the team in designing sketches and creating a [PopApp](https://marvelapp.com/pop/) prototype. As well as leading the software development process in creating the mobile application. 

## Duration 

January 2018 - May 2018

## Project Team member

Sha Li | YiHan Wu | Ian Beh | Joseph Dasuki | Noah Biniek


## Demo 

![](https://media.githubusercontent.com/media/clementpeihengtan/clement-tph/gh-pages/assets/article_images/2018-05-02-imedtrainer/Imedtrainer_demo.gif)



## Process

### Motivation

Diagnosis of diseases has increasingly relied on interpretation of medical images, such as X-rays, CT, and mammograms. It takes a long time, usually multiple years, to train medical students to master this skill. Acquisition of expertise in medical imaging largely relies on experience in reading medical images. However, current-day medical students do not have access to large quantity of well-labeled medical images after class. In addition, lack of experts in this field makes it difficult for medical students to get sufficient feedback about their performance. Therefore, an educational application providing high-quality medical images with feedback will potentially accelerate learning of medical-image interpretation.


### Methods

We interviewed two radiology faculty members and three medical students at the University of Minnesota to gain a better understanding of typical radiology training objects and processes. We conducted half-hour structured interviews with audio recording and additional field note-taking. Participants were asked about their experiences with radiology training and/or general medical training. We also observed how participants interacted with an app demo. All audio records were transcribed, and analyzed to extract open codes which were clustered and selected during the qualitative analysis. The key features of our app were shaped by the functions to overcome current training challenges we discovered through our qualitative analysis.

### Affinity Mapping

Based on the interviews and the contextual inquiries results, we conducted open mapping by taking time to group the users' needs and clustering the idea into its own catorgory. Below are the result of our research:

[![](https://github.com/clementpeihengtan/clement-tph/blob/gh-pages/assets/article_images/2018-05-02-imedtrainer/opencoding.png?raw=true)](https://github.com/clementpeihengtan/clement-tph/blob/gh-pages/assets/article_images/2018-05-02-imedtrainer/opencoding.png?raw=true)

We managed to categorize the open note into different clusters.

<div style="position: relative">
    <div style="float: left; width: 33.33%; text-align:center;">
        <img src="https://raw.githubusercontent.com/clementpeihengtan/clement-tph/gh-pages/assets/article_images/2018-05-02-imedtrainer/image_cluster.jpg">
        <p>Imaging Cluster</p>
    </div>
    <div style="float: left; width: 33.33%; text-align:center;">
        <img src="https://github.com/clementpeihengtan/clement-tph/blob/gh-pages/assets/article_images/2018-05-02-imedtrainer/app_feature_cluster.jpg?raw=true">
        <p>App Feature Cluster</p>
    </div>
    <div style="float: left; width: 33.33%; text-align:center;">
        <img src="https://github.com/clementpeihengtan/clement-tph/blob/gh-pages/assets/article_images/2018-05-02-imedtrainer/training_cluster.jpg?raw=true">
        <p>Training Procedure Cluster</p>
    </div>
</div>
<!--#### Imaging Cluster-->

<!--![](https://github.com/clementpeihengtan/clement-tph/blob/gh-pages/assets/article_images/2018-05-02-imedtrainer/image_cluster.png)-->

<!--#### App Feature Cluster-->

<!--![](https://github.com/clementpeihengtan/clement-tph/blob/gh-pages/assets/article_images/2018-05-02-imedtrainer/app_feature_cluster.jpg?raw=true)-->

<!--#### Training Procedure Cluster-->

<!--![](https://github.com/clementpeihengtan/clement-tph/blob/gh-pages/assets/article_images/2018-05-02-imedtrainer/training_cluster.jpg?raw=true)-->

### Ideation

Based on the clusters and design implications, we conducted an ideation process where we listed down all the practical and wild ideas. We came out with more than 100 ideas. From there, we removed some of the unfeasible one and group them into different categories as shown below

![](https://github.com/clementpeihengtan/clement-tph/blob/gh-pages/assets/article_images/2018-05-02-imedtrainer/implicationandideation.jpg?raw=true)

### Prototype

### Cognitive Walkthrough

### Final Design 

![](https://media.githubusercontent.com/media/clementpeihengtan/clement-tph/gh-pages/assets/article_images/2018-05-02-imedtrainer/Imedtrainer_demo.gif)
